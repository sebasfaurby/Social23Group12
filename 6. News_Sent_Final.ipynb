{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the CSV files\n",
    "Path_sentiment = os.getcwd()+'/Sentiment analysis'\n",
    "\n",
    "# Set the path to the folder containing the news_final_1 CSV file\n",
    "Path_news_final_1 = os.getcwd()\n",
    "\n",
    "# Importing the news_final_1 CSV file\n",
    "news_final_1 = pd.read_csv(Path_news_final_1+'/news_API_final.csv', sep = ';', encoding = 'utf-8')\n",
    "\n",
    "# List comprehension to find all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(Path_sentiment) if file.endswith('.csv')]\n",
    "\n",
    "# Store all the dataframes in one dataframe \n",
    "list_of_dfs = [pd.read_csv(os.path.join(Path_sentiment, csv_file)) for csv_file in csv_files]\n",
    "\n",
    "# Concatenate all the dataframes in one dataframe\n",
    "sentiment_df = pd.concat(list_of_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM_score\n",
       " 0    92126\n",
       " 1    55827\n",
       "-1    32383\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace typos in LLM_score\n",
    "sentiment_df['LLM_score'] = sentiment_df['LLM_score'].replace('0 Ul', 0)\n",
    "sentiment_df['LLM_score'] = sentiment_df['LLM_score'].replace('0 Ve', 0)\n",
    "\n",
    "# convert LLM_score to integer\n",
    "sentiment_df['LLM_score'] = sentiment_df['LLM_score'].astype('int32')\n",
    "\n",
    "# Check the value counts of LLM_score\n",
    "sentiment_df['LLM_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by date and company and summing and taking the mean of the LLM_score\n",
    "sentiment_agg = sentiment_df.groupby(['date', 'company'])['LLM_score'].agg(['sum', 'mean', 'count'])\n",
    "\n",
    "# Resetting the index\n",
    "sentiment_agg = sentiment_agg.reset_index()\n",
    "\n",
    "# Joining the news_final_1 dataframe with the sentiment_agg dataframe \n",
    "news_sent_merge = pd.merge(news_final_1, sentiment_agg,  how='inner', on=['date', 'company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the TickerNames_final CSV file\n",
    "Path_tickers = os.getcwd()+'/TickerNames_2022.csv'\n",
    "TickerNames_final = pd.read_csv(Path_tickers)\n",
    "\n",
    "# Set 'Name' column as the index of TickerNames_final\n",
    "TickerNames_final.set_index('Name', inplace=True)\n",
    "\n",
    "# Create a dictionary to map company names to tickers using the index\n",
    "ticker_mapping = TickerNames_final['Symbol'].to_dict()\n",
    "\n",
    "# Apply the mapping to the 'company' column\n",
    "news_sent_merge['Ticker'] = news_sent_merge['company'].map(ticker_mapping)\n",
    "\n",
    "# Convert the timestamp column to datetime\n",
    "news_sent_merge['date'] = pd.to_datetime(news_sent_merge['date'])\n",
    "\n",
    "# Create a timedelta to represent the GMT-4 offset\n",
    "gmt_minus_4 = timedelta(hours=-4)\n",
    "\n",
    "# Define a function to apply the conversion\n",
    "def convert_to_gmt_minus_4(timestamp):\n",
    "    converted_datetime = timestamp + gmt_minus_4\n",
    "    return converted_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Apply the conversion function to the timestamp column\n",
    "news_sent_merge['New_date'] = news_sent_merge['date'].apply(convert_to_gmt_minus_4)\n",
    "\n",
    "\n",
    "# Change column names\n",
    "news_sent_final = news_sent_merge[['New_date', 'Ticker', 'sum', 'mean']]\n",
    "colnames = ['date','Ticker','LLM_score_sum','LLM_score_mean']\n",
    "news_sent_final.columns = colnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save news_sent_final as a CSV file\n",
    "news_sent_final.to_csv(os.getcwd()+'News_sentiment_final.csv', sep = ';', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Master dataframe\n",
    "Path_Master = os.getcwd()+'/Final Scripts/Data processing/'\n",
    "\n",
    "Master_df = pd.read_csv(Path_Master+'Master_with_technicals_news.csv', encoding='utf-8')\n",
    "\n",
    "# Final dataframe\n",
    "Final_df = pd.merge(Master_df, news_sent_final,  how='left', on = ['date', 'Ticker'])\n",
    "\n",
    "# Count instances of LLM_score_sum\n",
    "Final_df['LLM_score_mean'].value_counts()\n",
    "\n",
    "# If LLM_score_mean is NaN, then it is set to 0 to indicate that there is no relevant news\n",
    "Final_df['LLM_score_mean'] = Final_df['LLM_score_mean'].fillna(0)\n",
    "Final_df['LLM_score_sum'] = Final_df['LLM_score_sum'].fillna(0)\n",
    "\n",
    "# Remove duplicates in Final_df\n",
    "Final_df = Final_df.drop_duplicates(subset=['date','Ticker'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final_df as a CSV file\n",
    "Final_df.to_csv('Final scripts/Final_df.csv', sep = ';', encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
